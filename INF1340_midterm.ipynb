{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJVA2GT5yEUovKeUUNV4jT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linforestli/text_analysis/blob/main/INF1340_midterm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npupwGSsZL64"
      },
      "outputs": [],
      "source": [
        "# Text analysis\n",
        "# functions to implement\n",
        "# word count (checked)\n",
        "# word frequency (checked)\n",
        "# top 10 most common words (checked)\n",
        "# avg sentence length (checked)\n",
        "# number of unique word (checked)\n",
        "# sentence count (checked)\n",
        "# lexical diversity\n",
        "# Readability score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_count(data: str) -> int:\n",
        "  '''\n",
        "  Return the number of words.\n",
        "  '''\n",
        "  words = data.split()\n",
        "  return len(words)"
      ],
      "metadata": {
        "id": "pAnOv3fs6t7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_count(data: str) -> int:\n",
        "  '''\n",
        "  Return the number of sentences in the text file.\n",
        "  '''\n",
        "  sentences = data.strip().split(\".\")\n",
        "  sentences = [item for item in sentences if item != \"\"]\n",
        "  return len(sentences)"
      ],
      "metadata": {
        "id": "M27ZX-Nd7Xrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unique_words(data: str) -> list:\n",
        "  '''\n",
        "  Return a list of unique words in the text file.\n",
        "  '''\n",
        "  for punc in ['.', ',', ';', ':', '!', '?', '(', ')', '\"', \"'\"]:\n",
        "      data = data.replace(punc, '')\n",
        "  words = data.lower().split()\n",
        "  unique = []\n",
        "  for word in words:\n",
        "    if word not in unique:\n",
        "      unique.append(word)\n",
        "  return unique"
      ],
      "metadata": {
        "id": "R3ksoDUl-vtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_len_sen(data: str) -> float:\n",
        "  '''\n",
        "  Return the average sentence length in the text file.\n",
        "  '''\n",
        "  sentences = data.strip().split(\".\")\n",
        "  sentences = [item for item in sentences if item != \"\"]\n",
        "  sen_len = []\n",
        "  for sentence in sentences:\n",
        "    words = sentence.split()\n",
        "    sen_len.append(len(words))\n",
        "  if len(sen_len) != 0:\n",
        "    return round(sum(sen_len) / len(sen_len), 2)\n",
        "  else:\n",
        "    return \"No sentences found\""
      ],
      "metadata": {
        "id": "3eA5lz15BBKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_freq(data: str) -> dict:\n",
        "  '''\n",
        "  Return a dictionary of word frequency in a text file.\n",
        "  '''\n",
        "  for punc in ['.', ',', ';', ':', '!', '?', '(', ')', '\"', \"'\"]:\n",
        "      data = data.replace(punc, '')\n",
        "  words = data.lower().split()\n",
        "  word_times = {}\n",
        "  for word in words:\n",
        "    if word in word_times:\n",
        "      word_times[word] += 1\n",
        "    else:\n",
        "      word_times[word] = 1\n",
        "  return word_times"
      ],
      "metadata": {
        "id": "zPaw83R2DhfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def most_common(data: str) -> list:\n",
        "  '''\n",
        "  Return a list of top 10 most common word in the text.\n",
        "  '''\n",
        "  word_times = word_freq(data)\n",
        "  keys = list(word_times.keys())\n",
        "  n = len(keys)\n",
        "  results = []\n",
        "\n",
        "  for i in range(n):\n",
        "    for j in range(0, n - i - 1):\n",
        "      if word_times[keys[j]] < word_times[keys[j + 1]]:\n",
        "        keys[j], keys[j + 1] = keys[j + 1], keys[j]\n",
        "\n",
        "  return keys[:10]"
      ],
      "metadata": {
        "id": "ZECE5_n7JHgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lexical_diversity(data: str) -> float:\n",
        "  '''\n",
        "  Return the lexical diversity of a given text.\n",
        "  LD = unique words / total words\n",
        "  '''\n",
        "  try:\n",
        "    LD = len(unique_words(data)) / word_count(data)\n",
        "    return round(LD, 2)\n",
        "  except Exception as e:\n",
        "    return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "1jPn9gymThK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def syllables_count(data: str) -> int:\n",
        "  '''\n",
        "  Count the total number of syllables in the text\n",
        "  '''\n",
        "  words = data.split()\n",
        "  total = 0\n",
        "  for word in words:\n",
        "    total += identify_syllable(word)\n",
        "  return total\n",
        "\n",
        "def identify_syllable(word: str) -> int:\n",
        "  '''\n",
        "  Count the approximate number of syllable in a word\n",
        "  '''\n",
        "  vowels = ['a', 'e', 'i', 'o', 'u']\n",
        "  count = 0\n",
        "  for i in range(1, len(word)):\n",
        "    if word[i] in vowels and word[i - 1] not in vowels:\n",
        "      count += 1\n",
        "  if len(word) == 1 and word in vowels:\n",
        "    count += 1\n",
        "  if count == 0:\n",
        "    count = 1\n",
        "  return count"
      ],
      "metadata": {
        "id": "UrGt16kscpAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readability_score(data: str) -> float:\n",
        "  '''\n",
        "  Return the approximate readability score of the text based on\n",
        "  Flesch-Kincaid Index.\n",
        "  '''\n",
        "  score = 206.835 - 1.015 * (word_count(data) / sentence_count(data)) - 84.6 * (\n",
        "      syllables_count(data) / word_count(data)\n",
        "  )\n",
        "  return round(score, 2)\n",
        "\n",
        "\n",
        "def explain_score(score: float) -> str:\n",
        "  '''\n",
        "  Match readability score with levels\n",
        "  '''\n",
        "  if score <= 10.0:\n",
        "    return \"Professional: Extremely difficult to read. Best understood by university graduates.\"\n",
        "  elif score <= 30.0:\n",
        "    return \"College graduate: Very difficult to read. Best understood by university graduates.\"\n",
        "  elif score <= 50.0:\n",
        "    return \"College: Difficult to read.\"\n",
        "  elif score <= 60.0:\n",
        "    return \"10th to 12th grade: Fairly difficult to read.\"\n",
        "  elif score <= 70.0:\n",
        "    return \"8th & 9th grade: Plain English. Easily understood by 13- to 15-year-old students.\"\n",
        "  elif score <= 80.0:\n",
        "    return \"7th grade: Fairly easy to read.\"\n",
        "  elif score <= 90.0:\n",
        "    return \"6th grade: Easy to read. Conversational English for consumers.\"\n",
        "  elif score <= 100.0:\n",
        "    return \"5th grade: Very easy to read. Easily understood by an average 11-year-old student.\"\n",
        "  else:\n",
        "    return \"Error\""
      ],
      "metadata": {
        "id": "d4rOZQarYJBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  input_fn = input('''\n",
        "  Enter the name of the input file, or choose from the following sample data:\n",
        "  1. The Life of Chuck by Stephen King (Excerpt)\n",
        "  2. Mr. Brown can Moo! can you? by Dr. Seuss\n",
        "  3. Advantage of the Union in Respect to Economy in Government by Alexander Hamilton\n",
        "  ''')\n",
        "  output_fn = input(\"Enter the desired name of the output file with extension: \")\n",
        "\n",
        "  if input_fn == '1':\n",
        "    input_fn = 'data/thelifeofchuck.txt'\n",
        "  elif input_fn == '2':\n",
        "    input_fn = 'data/Dr.Seuss.txt'\n",
        "  elif input_fn == '3':\n",
        "    input_fn = 'data/hamilton.txt'\n",
        "  else:\n",
        "    input_fn = input_fn\n",
        "\n",
        "  with open(input_fn, 'r') as f:\n",
        "    data = f.read()\n",
        "    wordcount = word_count(data)\n",
        "    sentencecount = sentence_count(data)\n",
        "    uniquewords = len(unique_words(data))\n",
        "    avglensen = avg_len_sen(data)\n",
        "    wordfreq = word_freq(data)\n",
        "    mostcommon = most_common(data)\n",
        "    lexicaldiversity = lexical_diversity(data)\n",
        "    readabilityscore = readability_score(data)\n",
        "\n",
        "  with open(output_fn, 'w') as f:\n",
        "    f.write(f\"Text analysis of {input_fn}\\n\")\n",
        "    f.write(f\"Word count: {wordcount}\\n\")\n",
        "    f.write(f\"Sentence count: {sentencecount}\\n\")\n",
        "    f.write(f\"Unique words count: {uniquewords}\\n\")\n",
        "    f.write(f\"Average sentence length (words per sentence): {avglensen}\\n\")\n",
        "    f.write(f\"Lexical diversity: {lexicaldiversity}\\n\")\n",
        "    f.write(f\"Readability score: {readabilityscore}\\n\")\n",
        "    f.write(f\"Readability level: {explain_score(readabilityscore)}\\n\")\n",
        "    f.write(f\"10 Most common words: \\n\")\n",
        "    for word in mostcommon:\n",
        "      f.write(f\"\\t{word}\\n\")\n",
        "    f.write(\"Word frequency: \\n\")\n",
        "    for key, value in wordfreq.items():\n",
        "      f.write(f\"\\t{key}: {value}\\n\")\n",
        "\n",
        "  with open(output_fn, 'r') as f:\n",
        "    print(f.read())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqA-jIyslWt3",
        "outputId": "f1bd6cfb-40f2-499b-b543-52716fb2433e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Enter the name of the input file, or choose from the following sample data:\n",
            "  1. The Life of Chuck by Stephen King (Excerpt)\n",
            "  2. Mr. Brown can Moo! can you? by Dr. Seuss\n",
            "  3. Advantage of the Union in Respect to Economy in Government by Alexander Hamilton\n",
            "  3\n",
            "Enter the desired name of the output file with extension: report.txt\n",
            "Text analysis of data/hamilton.txt\n",
            "Word count: 967\n",
            "Sentence count: 29\n",
            "Unique words count: 387\n",
            "Average sentence length (words per sentence): 33.34\n",
            "Lexical diversity: 0.4\n",
            "Readability score: 38.17\n",
            "Readability level: College: Difficult to read.\n",
            "10 Most common words: \n",
            "\tthe\n",
            "\tof\n",
            "\tto\n",
            "\ta\n",
            "\tbe\n",
            "\tthat\n",
            "\tand\n",
            "\twould\n",
            "\tin\n",
            "\twe\n",
            "Word frequency: \n",
            "\tto: 43\n",
            "\tthe: 74\n",
            "\tpeople: 3\n",
            "\tof: 58\n",
            "\tstate: 4\n",
            "\tnew: 4\n",
            "\tyork: 2\n",
            "\tas: 8\n",
            "\tconnected: 1\n",
            "\twith: 10\n",
            "\tsubject: 1\n",
            "\trevenue: 3\n",
            "\twe: 11\n",
            "\tmay: 8\n",
            "\tpropriety: 1\n",
            "\tconsider: 2\n",
            "\tthat: 18\n",
            "\teconomy: 2\n",
            "\tmoney: 1\n",
            "\tsaved: 1\n",
            "\tfrom: 5\n",
            "\tone: 8\n",
            "\tobject: 1\n",
            "\tbe: 25\n",
            "\tusefully: 1\n",
            "\tapplied: 1\n",
            "\tanother: 3\n",
            "\tand: 17\n",
            "\tthere: 9\n",
            "\twill: 9\n",
            "\tso: 3\n",
            "\tmuch: 3\n",
            "\tless: 5\n",
            "\tdrawn: 1\n",
            "\tpockets: 1\n",
            "\tif: 6\n",
            "\tstates: 9\n",
            "\tare: 4\n",
            "\tunited: 1\n",
            "\tunder: 2\n",
            "\tgovernment: 7\n",
            "\tbut: 2\n",
            "\tnational: 4\n",
            "\tcivil: 5\n",
            "\tlist: 1\n",
            "\tsupport: 2\n",
            "\tthey: 3\n",
            "\tdivided: 3\n",
            "\tinto: 7\n",
            "\tseveral: 2\n",
            "\tconfederacies: 4\n",
            "\tmany: 2\n",
            "\tdifferent: 3\n",
            "\tlists: 2\n",
            "\tprovided: 1\n",
            "\tfor--and: 1\n",
            "\teach: 4\n",
            "\tthem: 1\n",
            "\tprincipal: 1\n",
            "\tdepartments: 1\n",
            "\tcoextensive: 1\n",
            "\twhich: 11\n",
            "\twould: 14\n",
            "\tnecessary: 2\n",
            "\tfor: 1\n",
            "\ta: 26\n",
            "\twhole: 2\n",
            "\tentire: 1\n",
            "\tseparation: 2\n",
            "\tthirteen: 2\n",
            "\tunconnected: 1\n",
            "\tsovereignties: 1\n",
            "\tis: 9\n",
            "\tproject: 1\n",
            "\ttoo: 3\n",
            "\textravagant: 1\n",
            "\treplete: 1\n",
            "\tdanger: 1\n",
            "\thave: 4\n",
            "\tadvocates: 1\n",
            "\tideas: 1\n",
            "\tmen: 1\n",
            "\twho: 3\n",
            "\tspeculate: 1\n",
            "\tupon: 2\n",
            "\tdismemberment: 1\n",
            "\tempire: 2\n",
            "\tseem: 1\n",
            "\tgenerally: 1\n",
            "\tturned: 2\n",
            "\ttoward: 1\n",
            "\tthree: 2\n",
            "\tconfederacies--one: 1\n",
            "\tconsisting: 1\n",
            "\tfour: 3\n",
            "\tnorthern: 4\n",
            "\tmiddle: 1\n",
            "\tthird: 2\n",
            "\tfive: 1\n",
            "\tsouthern: 3\n",
            "\tlittle: 1\n",
            "\tprobability: 1\n",
            "\tgreater: 2\n",
            "\tnumber: 4\n",
            "\taccording: 1\n",
            "\tthis: 5\n",
            "\tdistribution: 1\n",
            "\tconfederacy: 7\n",
            "\tcomprise: 1\n",
            "\tan: 3\n",
            "\textent: 3\n",
            "\tterritory: 1\n",
            "\tlarger: 1\n",
            "\tthan: 10\n",
            "\tkingdom: 1\n",
            "\tgreat: 4\n",
            "\tbritain: 2\n",
            "\tno: 4\n",
            "\twell-informed: 1\n",
            "\tman: 1\n",
            "\tsuppose: 1\n",
            "\taffairs: 1\n",
            "\tsuch: 1\n",
            "\tcan: 4\n",
            "\tproperly: 2\n",
            "\tregulated: 1\n",
            "\tby: 5\n",
            "\tcomprehensive: 2\n",
            "\tin: 14\n",
            "\tits: 2\n",
            "\torgans: 1\n",
            "\tor: 3\n",
            "\tinstitutions: 2\n",
            "\thas: 2\n",
            "\tbeen: 2\n",
            "\tproposed: 3\n",
            "\tconvention: 1\n",
            "\twhen: 4\n",
            "\tdimensions: 1\n",
            "\tattain: 1\n",
            "\tcertain: 1\n",
            "\tmagnitude: 1\n",
            "\tit: 6\n",
            "\trequires: 1\n",
            "\tsame: 3\n",
            "\tenergy: 1\n",
            "\tforms: 1\n",
            "\tadministration: 1\n",
            "\trequisite: 1\n",
            "\tidea: 1\n",
            "\tadmits: 1\n",
            "\tnot: 5\n",
            "\tprecise: 1\n",
            "\tdemonstration: 1\n",
            "\tbecause: 1\n",
            "\trule: 1\n",
            "\tmeasure: 1\n",
            "\tmomentum: 1\n",
            "\tpower: 5\n",
            "\tany: 3\n",
            "\tgiven: 1\n",
            "\tindividuals: 1\n",
            "\tisland: 1\n",
            "\tnearly: 1\n",
            "\tcommensurate: 1\n",
            "\tsupposed: 1\n",
            "\tcontains: 1\n",
            "\tabout: 1\n",
            "\teight: 1\n",
            "\tmillions: 1\n",
            "\treflect: 1\n",
            "\tdegree: 1\n",
            "\tauthority: 1\n",
            "\trequired: 1\n",
            "\tdirect: 1\n",
            "\tpassions: 1\n",
            "\tlarge: 1\n",
            "\tsociety: 2\n",
            "\tpublic: 1\n",
            "\tgood: 1\n",
            "\tshall: 3\n",
            "\tsee: 1\n",
            "\treason: 1\n",
            "\tdoubt: 1\n",
            "\tlike: 1\n",
            "\tportion: 1\n",
            "\tsufficient: 1\n",
            "\tperform: 1\n",
            "\ttask: 1\n",
            "\tfar: 1\n",
            "\tmore: 6\n",
            "\tnumerous: 1\n",
            "\torganized: 1\n",
            "\texerted: 1\n",
            "\tcapable: 1\n",
            "\tdiffusing: 1\n",
            "\tforce: 1\n",
            "\tvery: 1\n",
            "\tmanner: 1\n",
            "\treproduce: 1\n",
            "\titself: 1\n",
            "\tevery: 3\n",
            "\tpart: 2\n",
            "\tjudicious: 1\n",
            "\tarrangement: 1\n",
            "\tsubordinate: 1\n",
            "\tsupposition: 2\n",
            "\tlikely: 1\n",
            "\trequire: 1\n",
            "\tstrengthened: 1\n",
            "\tprobable: 1\n",
            "\tpresents: 1\n",
            "\tus: 1\n",
            "\talternative: 1\n",
            "\tgeneral: 1\n",
            "\tunion: 1\n",
            "\tattend: 1\n",
            "\tcarefully: 1\n",
            "\tgeographical: 1\n",
            "\tcommercial: 1\n",
            "\tconsiderations: 1\n",
            "\tconjunction: 1\n",
            "\thabits: 1\n",
            "\tprejudices: 1\n",
            "\tled: 1\n",
            "\tconclude: 1\n",
            "\tcase: 1\n",
            "\tdisunion: 1\n",
            "\tmost: 2\n",
            "\tnaturally: 1\n",
            "\tleague: 2\n",
            "\tthemselves: 2\n",
            "\ttwo: 1\n",
            "\tgovernments: 1\n",
            "\teastern: 1\n",
            "\tall: 3\n",
            "\tcauses: 1\n",
            "\tform: 1\n",
            "\tlinks: 1\n",
            "\tsympathy: 1\n",
            "\tconnection: 2\n",
            "\tcertainty: 1\n",
            "\texpected: 1\n",
            "\tunite: 1\n",
            "\tsituated: 1\n",
            "\tshe: 3\n",
            "\tnever: 1\n",
            "\tunwise: 1\n",
            "\tenough: 1\n",
            "\toppose: 1\n",
            "\tfeeble: 1\n",
            "\tunsupported: 1\n",
            "\tflank: 1\n",
            "\tweight: 2\n",
            "\tother: 1\n",
            "\tobvious: 1\n",
            "\treasons: 1\n",
            "\tfacilitate: 1\n",
            "\ther: 10\n",
            "\taccession: 1\n",
            "\tjersey: 2\n",
            "\tsmall: 1\n",
            "\tthink: 2\n",
            "\tbeing: 2\n",
            "\tfrontier: 2\n",
            "\topposition: 1\n",
            "\tstill: 1\n",
            "\tpowerful: 1\n",
            "\tcombination: 1\n",
            "\tnor: 1\n",
            "\tdo: 1\n",
            "\tappear: 2\n",
            "\tobstacles: 1\n",
            "\tadmission: 1\n",
            "\teven: 1\n",
            "\tpennsylvania: 3\n",
            "\tstrong: 1\n",
            "\tinducements: 1\n",
            "\tjoin: 1\n",
            "\tactive: 1\n",
            "\tforeign: 1\n",
            "\tcommerce: 2\n",
            "\ton: 3\n",
            "\tbasis: 1\n",
            "\town: 1\n",
            "\tnavigation: 2\n",
            "\ttrue: 1\n",
            "\tpolicy: 2\n",
            "\tcoincides: 1\n",
            "\topinions: 1\n",
            "\tdispositions: 1\n",
            "\tcitizens: 1\n",
            "\tvarious: 1\n",
            "\tcircumstances: 1\n",
            "\tinterested: 1\n",
            "\tencouragement: 1\n",
            "\tprefer: 1\n",
            "\tsystem: 1\n",
            "\tgive: 2\n",
            "\tunlimited: 1\n",
            "\tscope: 1\n",
            "\tnations: 2\n",
            "\tcarriers: 1\n",
            "\twell: 1\n",
            "\tpurchasers: 1\n",
            "\ttheir: 1\n",
            "\tcommodities: 1\n",
            "\tchoose: 1\n",
            "\tconfound: 1\n",
            "\tinterests: 1\n",
            "\tadverse: 1\n",
            "\tmust: 3\n",
            "\tat: 1\n",
            "\tevents: 1\n",
            "\tdeem: 1\n",
            "\tconsistent: 1\n",
            "\tsafety: 1\n",
            "\texposed: 1\n",
            "\tside: 1\n",
            "\ttowards: 2\n",
            "\tweaker: 1\n",
            "\trather: 1\n",
            "\tstronger: 1\n",
            "\tfairest: 1\n",
            "\tchance: 1\n",
            "\tavoid: 1\n",
            "\tflanders: 1\n",
            "\tamerica: 1\n",
            "\twhatever: 1\n",
            "\tdetermination: 1\n",
            "\tincludes: 1\n",
            "\tlikelihood: 1\n",
            "\tsouth: 1\n",
            "\tnothing: 1\n",
            "\tevident: 1\n",
            "\table: 1\n",
            "\tbetter: 1\n",
            "\thalf: 1\n",
            "\treflection: 1\n",
            "\tobviating: 1\n",
            "\tobjection: 2\n",
            "\tplan: 1\n",
            "\tfounded: 1\n",
            "\tprinciple: 1\n",
            "\texpense: 1\n",
            "\thowever: 1\n",
            "\tcome: 1\n",
            "\ttake: 3\n",
            "\tnearer: 1\n",
            "\tview: 3\n",
            "\tlight: 1\n",
            "\tstand: 1\n",
            "\tmistaken: 1\n",
            "\tground: 1\n",
            "\taddition: 1\n",
            "\tconsideration: 1\n",
            "\tplurality: 1\n",
            "\tpersons: 1\n",
            "\tnecessarily: 1\n",
            "\temployed: 1\n",
            "\tguard: 1\n",
            "\tinland: 1\n",
            "\tcommunication: 1\n",
            "\tbetween: 1\n",
            "\tagainst: 1\n",
            "\tillicit: 1\n",
            "\ttrade: 1\n",
            "\ttime: 1\n",
            "\tinfallibly: 1\n",
            "\tspring: 1\n",
            "\tup: 1\n",
            "\tout: 1\n",
            "\tnecessities: 1\n",
            "\talso: 1\n",
            "\tmilitary: 1\n",
            "\testablishments: 1\n",
            "\tshown: 1\n",
            "\tunavoidably: 1\n",
            "\tresult: 1\n",
            "\tjealousies: 1\n",
            "\tconflicts: 1\n",
            "\tclearly: 1\n",
            "\tdiscover: 1\n",
            "\tinjurious: 1\n",
            "\ttranquillity: 1\n",
            "\tliberty: 1\n",
            "\tpublius: 1\n",
            "\n"
          ]
        }
      ]
    }
  ]
}