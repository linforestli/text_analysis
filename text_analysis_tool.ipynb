{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkIDImELNDgQHy36Y0UrgZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linforestli/text_analysis/blob/main/text_analysis_tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "npupwGSsZL64"
      },
      "outputs": [],
      "source": [
        "###################################################################\n",
        "# University of Toronto\n",
        "# Faculty of Information\n",
        "# Master of Information Program\n",
        "# INF 1340H - Programming for Data Science\n",
        "# Student Name: Linrong Li\n",
        "# Student Number: 1006697969\n",
        "#\n",
        "#\n",
        "#\n",
        "# Midterm Project\n",
        "# Purpose: Text analysis tool\n",
        "# Date Created: 2024/10/10\n",
        "# Date Modified: 2024/10/10\n",
        "###################################################################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_count(data: str) -> int:\n",
        "  '''\n",
        "  Return the number of words.\n",
        "  '''\n",
        "  words = data.split()\n",
        "  return len(words)"
      ],
      "metadata": {
        "id": "pAnOv3fs6t7q"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_count(data: str) -> int:\n",
        "  '''\n",
        "  Return the number of sentences in the text file.\n",
        "  '''\n",
        "  sentences = data.strip().split(\".\")\n",
        "  sentences = [item for item in sentences if item != \"\"]\n",
        "  return len(sentences)"
      ],
      "metadata": {
        "id": "M27ZX-Nd7Xrh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unique_words(data: str) -> list:\n",
        "  '''\n",
        "  Return a list of unique words in the text file.\n",
        "  '''\n",
        "  for punc in ['.', ',', ';', ':', '!', '?', '(', ')', '\"', \"'\"]:\n",
        "      data = data.replace(punc, '')\n",
        "  words = data.lower().split()\n",
        "  unique = []\n",
        "  for word in words:\n",
        "    if word not in unique:\n",
        "      unique.append(word)\n",
        "  return unique"
      ],
      "metadata": {
        "id": "R3ksoDUl-vtd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_len_sen(data: str) -> float:\n",
        "  '''\n",
        "  Return the average sentence length in the text file.\n",
        "  '''\n",
        "  sentences = data.strip().split(\".\")\n",
        "  sentences = [item for item in sentences if item != \"\"]\n",
        "  sen_len = []\n",
        "  for sentence in sentences:\n",
        "    words = sentence.split()\n",
        "    sen_len.append(len(words))\n",
        "  if len(sen_len) != 0:\n",
        "    return round(sum(sen_len) / len(sen_len), 2)\n",
        "  else:\n",
        "    return \"No sentences found\""
      ],
      "metadata": {
        "id": "3eA5lz15BBKd"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_freq(data: str) -> dict:\n",
        "  '''\n",
        "  Return a dictionary of word frequency in a text file.\n",
        "  '''\n",
        "  for punc in ['.', ',', ';', ':', '!', '?', '(', ')', '\"', \"'\"]:\n",
        "      data = data.replace(punc, '')\n",
        "  words = data.lower().split()\n",
        "  word_times = {}\n",
        "  for word in words:\n",
        "    if word in word_times:\n",
        "      word_times[word] += 1\n",
        "    else:\n",
        "      word_times[word] = 1\n",
        "  return word_times"
      ],
      "metadata": {
        "id": "zPaw83R2DhfA"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def most_common(data: str) -> list:\n",
        "  '''\n",
        "  Return a list of top 10 most common word in the text.\n",
        "  '''\n",
        "  word_times = word_freq(data)\n",
        "  keys = list(word_times.keys())\n",
        "  n = len(keys)\n",
        "  results = []\n",
        "\n",
        "  for i in range(n):\n",
        "    for j in range(0, n - i - 1):\n",
        "      if word_times[keys[j]] < word_times[keys[j + 1]]:\n",
        "        keys[j], keys[j + 1] = keys[j + 1], keys[j]\n",
        "\n",
        "  return keys[:10]"
      ],
      "metadata": {
        "id": "ZECE5_n7JHgY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lexical_diversity(data: str) -> float:\n",
        "  '''\n",
        "  Return the lexical diversity of a given text.\n",
        "  LD = unique words / total words\n",
        "  '''\n",
        "  try:\n",
        "    LD = len(unique_words(data)) / word_count(data)\n",
        "    return round(LD, 2)\n",
        "  except Exception as e:\n",
        "    return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "1jPn9gymThK3"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def syllables_count(data: str) -> int:\n",
        "  '''\n",
        "  Count the total number of syllables in the text\n",
        "  '''\n",
        "  words = data.split()\n",
        "  total = 0\n",
        "  for word in words:\n",
        "    total += identify_syllable(word)\n",
        "  return total\n",
        "\n",
        "def identify_syllable(word: str) -> int:\n",
        "  '''\n",
        "  Count the approximate number of syllable in a word\n",
        "  '''\n",
        "  vowels = ['a', 'e', 'i', 'o', 'u', 'y']\n",
        "  count = 0\n",
        "  for i in range(1, len(word)):\n",
        "    if word[i] in vowels and word[i - 1] not in vowels:\n",
        "      count += 1\n",
        "  if len(word) == 1 and word in vowels:\n",
        "    count += 1\n",
        "  if count == 0:\n",
        "    count = 1\n",
        "  return count"
      ],
      "metadata": {
        "id": "UrGt16kscpAj"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readability_score(data: str) -> float:\n",
        "  '''\n",
        "  Return the approximate readability score of the text based on\n",
        "  Flesch-Kincaid Index.\n",
        "  '''\n",
        "  score = 206.835 - 1.015 * (word_count(data) / sentence_count(data)) - 84.6 * (\n",
        "      syllables_count(data) / word_count(data)\n",
        "  )\n",
        "  return round(score, 2)\n",
        "\n",
        "def explain_score(score: float) -> str:\n",
        "  '''\n",
        "  Match readability score with levels\n",
        "  '''\n",
        "  if score <= 10.0:\n",
        "    return \"Professional: Extremely difficult to read. Best understood by university graduates.\"\n",
        "  elif score <= 30.0:\n",
        "    return \"College graduate: Very difficult to read. Best understood by university graduates.\"\n",
        "  elif score <= 50.0:\n",
        "    return \"College: Difficult to read.\"\n",
        "  elif score <= 60.0:\n",
        "    return \"10th to 12th grade: Fairly difficult to read.\"\n",
        "  elif score <= 70.0:\n",
        "    return \"8th & 9th grade: Plain English. Easily understood by 13- to 15-year-old students.\"\n",
        "  elif score <= 80.0:\n",
        "    return \"7th grade: Fairly easy to read.\"\n",
        "  elif score <= 90.0:\n",
        "    return \"6th grade: Easy to read. Conversational English for consumers.\"\n",
        "  elif score <= 100.0:\n",
        "    return \"5th grade: Very easy to read. Easily understood by an average 11-year-old student.\"\n",
        "  else:\n",
        "    return \"Error\""
      ],
      "metadata": {
        "id": "d4rOZQarYJBk"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def input_file() -> str:\n",
        "  '''\n",
        "  Get the input file used in the analysis from the user\n",
        "  '''\n",
        "  input_fn = input('''\n",
        "  Enter the name of the input file with extension, or choose from the following sample data:\n",
        "  1. The Life of Chuck by Stephen King (Excerpt)\n",
        "  2. Mr. Brown can Moo! can you? by Dr. Seuss\n",
        "  3. Advantage of the Union in Respect to Economy in Government by Alexander Hamilton\n",
        "  ''')\n",
        "\n",
        "  if input_fn == '1':\n",
        "    input_fn = 'data/thelifeofchuck.txt'\n",
        "  elif input_fn == '2':\n",
        "    input_fn = 'data/Dr.Seuss.txt'\n",
        "  elif input_fn == '3':\n",
        "    input_fn = 'data/hamilton.txt'\n",
        "  else:\n",
        "    input_fn = input_fn\n",
        "\n",
        "  return input_fn"
      ],
      "metadata": {
        "id": "H-9IM2cZu6DO"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output_file() -> str:\n",
        "  '''\n",
        "  Get the output file name from the user\n",
        "  '''\n",
        "  output_fn = input(\"Enter the desired name of the output file with extension: \")\n",
        "  return output_fn"
      ],
      "metadata": {
        "id": "FwVHHhybv9hQ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  input_fn = input_file()\n",
        "  output_fn = output_file()\n",
        "\n",
        "  with open(input_fn, 'r') as f:\n",
        "    data = f.read()\n",
        "    wordcount = word_count(data)\n",
        "    sentencecount = sentence_count(data)\n",
        "    uniquewords = len(unique_words(data))\n",
        "    avglensen = avg_len_sen(data)\n",
        "    wordfreq = word_freq(data)\n",
        "    mostcommon = most_common(data)\n",
        "    lexicaldiversity = lexical_diversity(data)\n",
        "    readabilityscore = readability_score(data)\n",
        "\n",
        "  with open(output_fn, 'w') as f:\n",
        "    f.write(f\"Text analysis of {input_fn}\\n\")\n",
        "    f.write(f\"Word count: {wordcount}\\n\")\n",
        "    f.write(f\"Sentence count: {sentencecount}\\n\")\n",
        "    f.write(f\"Unique words count: {uniquewords}\\n\")\n",
        "    f.write(f\"Average sentence length (words per sentence): {avglensen}\\n\")\n",
        "    f.write(f\"Lexical diversity: {lexicaldiversity}\\n\")\n",
        "    f.write(f\"Readability score: {readabilityscore}\\n\")\n",
        "    f.write(f\"Readability level: {explain_score(readabilityscore)}\\n\")\n",
        "    f.write(f\"10 Most common words: \\n\")\n",
        "    for word in mostcommon:\n",
        "      f.write(f\"\\t{word}\\n\")\n",
        "    f.write(\"Word frequency: \\n\")\n",
        "    for key, value in wordfreq.items():\n",
        "      f.write(f\"\\t{key}: {value}\\n\")\n",
        "\n",
        "  with open(output_fn, 'r') as f:\n",
        "    print(f.read())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n",
        "\n"
      ],
      "metadata": {
        "id": "oqA-jIyslWt3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}