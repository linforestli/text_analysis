# -*- coding: utf-8 -*-
"""text_analysis_tool.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/linforestli/text_analysis/blob/main/text_analysis_tool.ipynb
"""

###################################################################
# University of Toronto
# Faculty of Information
# Master of Information Program
# INF 1340H - Programming for Data Science
# Student Name: Linrong Li
# Student Number: 1006697969
#
#
#
# Midterm Project
# Purpose: Text analysis tool
# Date Created: 2024/10/10
# Date Modified: 2024/10/10
###################################################################

def word_count(data: str) -> int:
  '''
  Return the number of words.
  '''
  words = data.split()
  return len(words)

def sentence_count(data: str) -> int:
  '''
  Return the number of sentences in the text file.
  '''
  sentences = data.strip().split(".")
  sentences = [item for item in sentences if item != ""]
  return len(sentences)

def unique_words(data: str) -> list:
  '''
  Return a list of unique words in the text file.
  '''
  for punc in ['.', ',', ';', ':', '!', '?', '(', ')', '"', "'"]:
      data = data.replace(punc, '')
  words = data.lower().split()
  unique = []
  for word in words:
    if word not in unique:
      unique.append(word)
  return unique

def avg_len_sen(data: str) -> float:
  '''
  Return the average sentence length in the text file.
  '''
  sentences = data.strip().split(".")
  sentences = [item for item in sentences if item != ""]
  sen_len = []
  for sentence in sentences:
    words = sentence.split()
    sen_len.append(len(words))
  if len(sen_len) != 0:
    return round(sum(sen_len) / len(sen_len), 2)
  else:
    return "No sentences found"

def word_freq(data: str) -> dict:
  '''
  Return a dictionary of word frequency in a text file.
  '''
  for punc in ['.', ',', ';', ':', '!', '?', '(', ')', '"', "'"]:
      data = data.replace(punc, '')
  words = data.lower().split()
  word_times = {}
  for word in words:
    if word in word_times:
      word_times[word] += 1
    else:
      word_times[word] = 1
  return word_times

def most_common(data: str) -> list:
  '''
  Return a list of top 10 most common word in the text.
  '''
  word_times = word_freq(data)
  keys = list(word_times.keys())
  n = len(keys)
  results = []

  for i in range(n):
    for j in range(0, n - i - 1):
      if word_times[keys[j]] < word_times[keys[j + 1]]:
        keys[j], keys[j + 1] = keys[j + 1], keys[j]

  return keys[:10]

def lexical_diversity(data: str) -> float:
  '''
  Return the lexical diversity of a given text.
  LD = unique words / total words
  '''
  try:
    LD = len(unique_words(data)) / word_count(data)
    return round(LD, 2)
  except Exception as e:
    return f"Error: {str(e)}"

def syllables_count(data: str) -> int:
  '''
  Count the total number of syllables in the text
  '''
  words = data.split()
  total = 0
  for word in words:
    total += identify_syllable(word)
  return total

def identify_syllable(word: str) -> int:
  '''
  Count the approximate number of syllable in a word
  '''
  vowels = ['a', 'e', 'i', 'o', 'u', 'y']
  count = 0
  for i in range(1, len(word)):
    if word[i] in vowels and word[i - 1] not in vowels:
      count += 1
  if len(word) == 1 and word in vowels:
    count += 1
  if count == 0:
    count = 1
  return count

def readability_score(data: str) -> float:
  '''
  Return the approximate readability score of the text based on
  Flesch-Kincaid Index.
  '''
  score = 206.835 - 1.015 * (word_count(data) / sentence_count(data)) - 84.6 * (
      syllables_count(data) / word_count(data)
  )
  return round(score, 2)

def explain_score(score: float) -> str:
  '''
  Match readability score with levels
  '''
  if score <= 10.0:
    return "Professional: Extremely difficult to read. Best understood by university graduates."
  elif score <= 30.0:
    return "College graduate: Very difficult to read. Best understood by university graduates."
  elif score <= 50.0:
    return "College: Difficult to read."
  elif score <= 60.0:
    return "10th to 12th grade: Fairly difficult to read."
  elif score <= 70.0:
    return "8th & 9th grade: Plain English. Easily understood by 13- to 15-year-old students."
  elif score <= 80.0:
    return "7th grade: Fairly easy to read."
  elif score <= 90.0:
    return "6th grade: Easy to read. Conversational English for consumers."
  elif score <= 100.0:
    return "5th grade: Very easy to read. Easily understood by an average 11-year-old student."
  else:
    return "Error"

def input_file() -> str:
  '''
  Get the input file used in the analysis from the user
  '''
  input_fn = input('''
  Enter the name of the input file with extension, or choose from the following sample data:
  1. The Life of Chuck by Stephen King (Excerpt)
  2. Mr. Brown can Moo! can you? by Dr. Seuss
  3. Advantage of the Union in Respect to Economy in Government by Alexander Hamilton
  ''')

  if input_fn == '1':
    input_fn = 'data/thelifeofchuck.txt'
  elif input_fn == '2':
    input_fn = 'data/Dr.Seuss.txt'
  elif input_fn == '3':
    input_fn = 'data/hamilton.txt'
  else:
    input_fn = input_fn

  return input_fn

def output_file() -> str:
  '''
  Get the output file name from the user
  '''
  output_fn = input("Enter the desired name of the output file with extension: ")
  return output_fn

def main():
  input_fn = input_file()
  output_fn = output_file()

  with open(input_fn, 'r') as f:
    data = f.read()
    wordcount = word_count(data)
    sentencecount = sentence_count(data)
    uniquewords = len(unique_words(data))
    avglensen = avg_len_sen(data)
    wordfreq = word_freq(data)
    mostcommon = most_common(data)
    lexicaldiversity = lexical_diversity(data)
    readabilityscore = readability_score(data)

  with open(output_fn, 'w') as f:
    f.write(f"Text analysis of {input_fn}\n")
    f.write(f"Word count: {wordcount}\n")
    f.write(f"Sentence count: {sentencecount}\n")
    f.write(f"Unique words count: {uniquewords}\n")
    f.write(f"Average sentence length (words per sentence): {avglensen}\n")
    f.write(f"Lexical diversity: {lexicaldiversity}\n")
    f.write(f"Readability score: {readabilityscore}\n")
    f.write(f"Readability level: {explain_score(readabilityscore)}\n")
    f.write(f"10 Most common words: \n")
    for word in mostcommon:
      f.write(f"\t{word}\n")
    f.write("Word frequency: \n")
    for key, value in wordfreq.items():
      f.write(f"\t{key}: {value}\n")

  with open(output_fn, 'r') as f:
    print(f.read())

if __name__ == "__main__":
  main()